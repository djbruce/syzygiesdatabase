---
layout: default
<!-- title: jmcglone.com -->
cv: passive
notes: passive
contact: passive
description: Syzygy Database
---
<!-- <div class="jumbotron"> -->
<div class="row marketing">
<div class="col-sm-3">
	<img  class="img-circle avatar" alt="DJ Bruce" src="img/djbruce.jpg">
	</div>
	<div itemscope itemtype="http://data-vocabulary.org/Person" class="col-sm-9">
	<p>A fundamental open question about syzygies is to describe the Betti
		table of projective space under the degree d Veronese embedding. This
		is fully understood for the case of a projective line, but even for a
		projective plane a full description is unknown. For the projective
		plane, the issue is that the number of variables grows quadratically
		with d, and so the computational complexity ratchets up quickly. For
		instance, when d is at most 3, one can compute the entire Betti table
		with paper and pencil; when d is 4, Macaulay2 competes the Betti table
		in about 30 seconds. Yet even when d is 5, our computation in Macaulay2
		fails to terminate.
		</br>
		</br>
		The goal of this project is to compute (or partially compute) the Betti
		tables of Veronese embeddings of projective spaces via an alternate
		method. Instead of computing the free resolutions, we consider individual multigraded strands, 
		computing individual multigraded Betti numbers. From these finer invariants we are then able to
		recover both the standard graded Betti numbers, but also the associated Schur functions. 
		The advantage to this approach is twofold:
		<ul>
			<li> First, it moves us from a symbolic algebra to a linear algebra problem, and this allows us to capitalize on some of the incredible technology from numerical linear algebra. </li>
			<li> Second, it breaks the necessary computations up into smaller pieces making it ideal for parallelized and high throughput computing.  </li>
		</ul>
		Currently, we combine sparse, numerical linear
		algebra (via QR and LU factorization algorithms) with high throughput, and high
		performance computing (via HTCondor) to implement this method effectively. (See 
		<a href="approach.html">Our Approach</a> page for a more in-depth description of our methodology.)
		</br>
		</br>
		While others [1] have also recently implemented similar ideas regarding the computation of graded Betti numbers, our approach has a few additional benefits,
		one being the Schur function data. As d increases the graded and multigraded Betti numbers of the Veronese embedding grow quickly, becoming so large and numerous as to be difficult to work with. 
		In particular, the size of the individual Betti numbers &mdash; in the hundreds of millions &mdash; obscures much of the underlying structure and patterns. However, packaging this data via the associated Schur functions, 
		makes the data easier to work with. This has allowed us to (conjecturally) glimpse some of the underlying structure of these syzygies.
		</br>
		</br>
		Our belief in generating this experimental data  is that it will lead to new conjectures about the syzygies of Veroneses. (See the <a href="conjectures.html">Conjectures</a> page for a list of conjectures and questions we have raised.) 
		Thus we are content working with numerical algorithms, despite the potential for accidentally rounding a minuscule value down to zero. Throughout, we try to clearly differentiate between the
		Betti numbers that have been computed symbolically (e.g. by Gr&ouml;obner
		basis algorithms) from those that were computed numerically. (Note: Our Schur function methods allow us to catch and correct most small rounding errors. See Our Approach for further description.)
		</p>	
		
	
	</div>
</div>
<!-- </div> -->
